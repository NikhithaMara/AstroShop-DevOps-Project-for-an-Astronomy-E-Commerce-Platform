🌍 Why Terraform?
Using the AWS Console to create infrastructure is fine for just 1 or 2 resources. But what happens when you need to manage dozens or hundreds of resources? It becomes error-prone, inconsistent, and hard to scale.
This is where Infrastructure as Code (IaC) comes in — and Terraform is one of the most powerful tools in this space.
Terraform is a cloud-agnostic IaC tool that allows you to define and manage your cloud infrastructure using code. It uses HashiCorp Configuration Language (HCL) to declare resources in a readable, version-controllable way — enabling automation, collaboration, and repeatability.

⚙️ Terraform Lifecycle Commands
Here’s a quick overview of the typical Terraform workflow:
* terraform init: Initializes the working directory, downloads the necessary provider plugins (e.g., AWS), sets up the backend (for remote state), and checks for syntax issues.
* terraform plan: A dry run that shows what changes Terraform will make to your infrastructure — without actually applying them.(Showing wghat it does when applied)
* terraform apply: creates/updates the resources on cloud provider(AWS) by making api calls with cloud provider.

Behind the scenes, Terraform makes API calls to  cloud provider to provision and manage infrastructure based on your defined configuration.

✅ AWS Authentication
Before Terraformb creates resources on AWS , you need to authenticate with AWS else in which account it creates.
This has been completed by configuring the AWS CLI using access key and secret access key credentials.

📦 Terraform State File
Terraform tracks all created infrastructure in a state file. This file acts as a source of truth for the current state of your AWS resources.
When you run terraform apply, Terraform saves the resource metadata in a local file named state file
This file is stored locally by default, meaning it's tied to the user/machine that ran the apply.

If another user modifies the main.tf and runs terraform apply without access to the original state file, Terraform assumes the 
infrastructure doesn’t exist and may try to recreate it. This can lead to resource duplication or conflicts, especially in a team setting.

🌐 Why Use a Remote State File in Terraform?
By default, Terraform stores the state file locally on the machine where terraform apply is run. This creates challenges when multiple DevOps engineers work on the same infrastructure.

⚠️ The Problem with Local State Files
Suppose DevOps Engineer A runs terraform apply to create resources.
Terraform creates and tracks these resources using a local terraform.tfstate file on Engineer A’s machine.
Now, if DevOps Engineer B wants to update the same infrastructure and runs terraform apply on their machine:
Their local state file is empty. Terraform doesn’t know that the resources already exist. This can lead to duplicate resource creation, conflicts, and confusion.

🔐 Why Not Share the State File via GitHub?
Sharing the state file using version control (e.g., GitHub) is not recommended:
The state file contains sensitive information, such as IP addresses, AWS resource IDs, Potential secrets and metadata
Committing it to a github repository creates security vulnerabilities.

✅ The Solution: Remote Backend with S3 + DynamoDB
To solve this, we use a remote backend, which allows all DevOps engineers to share and update a centralized state file.
How it works:
Configure a remote backend using Amazon S3.
Store the terraform.tfstate file in an S3 bucket.
Add a backend.tf file (or define the backend in main.tf) to set this up.
Terraform will read and write to the remote state file in S3, rather than keeping it locally.
Example Scenario:
Engineer A applies main.tf — Terraform creates resources and updates the state file in S3.
Engineer B then applies main.tf with changes — Terraform checks the remote state in S3 and makes changes based on the current state, avoiding duplication.

🔒 What If Two Engineers Apply at the Same Time?
If multiple engineers apply changes at the same time, it could lead to race conditions. To avoid this:
Use DynamoDB for state locking.
When one engineer runs terraform apply, Terraform:
Creates a lock record in DynamoDB.
Prevents others from applying until the first execution is finished.
Once the apply is complete, the lock is released, and the next engineer can proceed.

🧱 Terraform Module Structure Overview
Any Terraform configuration (typically written in main.tf) generally consists of the following key sections:
🔌 Provider:
Defines which cloud provider you're using (e.g., AWS).
Refer to the AWS Terraform Provider documentation to understand available services and configuration.
📦 Variables:
Instead of hardcoding values, define input variables in a separate variables.tf file. This improves reusability and flexibility.
📚 Modules:
If the same Terraform logic needs to be reused across projects or environments, define it as a module.
Then, call it in your Terraform file using the module block with a source path (local or remote).
📤 Outputs:
Define the values you want Terraform to print after execution — such as IP addresses, ARNs, or resource names.

